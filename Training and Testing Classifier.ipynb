{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5131f9a",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3813a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63639c32",
   "metadata": {},
   "source": [
    "Sets the defualt seed to stop randomness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562c280e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1acfa7f4530>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = torch.default_generator\n",
    "rng.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46ccf2",
   "metadata": {},
   "source": [
    "Load tokeniser and model from hugging face (replace text to change classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2425a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at muhtasham/bert-small-finetuned-wnut17-ner and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"muhtasham/bert-small-finetuned-wnut17-ner\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained('muhtasham/bert-small-finetuned-wnut17-ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b5307",
   "metadata": {},
   "source": [
    "Load and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ae3a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset liar (C:/Users/Amy/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9577261b3078441a956150013365cc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"liar\")\n",
    "training = dataset[\"train\"]\n",
    "testing = dataset[\"test\"]\n",
    "train = pd.DataFrame(training)\n",
    "test = pd.DataFrame(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab76ef",
   "metadata": {},
   "source": [
    "Training for binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b1d099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\AppData\\Local\\Temp\\ipykernel_11124\\2718373583.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"statement\"][i] = removed\n",
      "C:\\Users\\Amy\\AppData\\Local\\Temp\\ipykernel_11124\\2718373583.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"statement\"][i] = removed\n"
     ]
    }
   ],
   "source": [
    "# Replace all labels with either 1 or 0\n",
    "train[\"label\"] = train[\"label\"].replace(1,0)\n",
    "train[\"label\"] = train[\"label\"].replace(2,1)\n",
    "train[\"label\"] = train[\"label\"].replace(3,1)\n",
    "train[\"label\"] = train[\"label\"].replace(4,0)\n",
    "train[\"label\"] = train[\"label\"].replace(5,0)\n",
    "# Same for testing data\n",
    "test[\"label\"] = test[\"label\"].replace(1,0)\n",
    "test[\"label\"] = test[\"label\"].replace(2,1)\n",
    "test[\"label\"] = test[\"label\"].replace(3,1)\n",
    "test[\"label\"] = test[\"label\"].replace(4,0)\n",
    "test[\"label\"] = test[\"label\"].replace(5,0)\n",
    "# Training data preprocessing\n",
    "for i in range(len(train.index)):\n",
    "    # Remove punctuation\n",
    "    removed = re.sub(r'[^\\w\\s]', '', train[\"statement\"][i].lower())\n",
    "    train[\"statement\"][i] = removed\n",
    "train2 = train[[\"label\"]].copy()\n",
    "values = []\n",
    "for i in range(len(train.index)):\n",
    "    # Tokenise text\n",
    "    state = tokenizer.encode(train[\"statement\"][i] , return_tensors = \"pt\")\n",
    "    # Run tokenised text through BERT model\n",
    "    state = model(state)\n",
    "    # Get values and append to list\n",
    "    values.append(state.logits.detach().numpy())\n",
    "train_values =  np.concatenate(values)\n",
    "#Testing data preprocessing\n",
    "for i in range(len(test.index)):\n",
    "    # Remove Punctuation\n",
    "    removed = re.sub(r'[^\\w\\s]', '', test[\"statement\"][i].lower())\n",
    "    test[\"statement\"][i] = removed\n",
    "test2 = test[[\"label\"]].copy()\n",
    "values = []\n",
    "for i in range(len(test.index)):\n",
    "    # Tokenise text\n",
    "    state = tokenizer.encode(test[\"statement\"][i] , return_tensors = \"pt\")\n",
    "    # Run tokenised text through BERT model\n",
    "    state = model(state)\n",
    "    # Get values and append to list\n",
    "    values.append(state.logits.detach().numpy())\n",
    "test_values =  np.concatenate(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b7d58",
   "metadata": {},
   "source": [
    "Fitting the model (binary classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b854baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, class_weight='balanced', gamma=1, probability=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalise values and change to numpy array\n",
    "x_train = preprocessing.normalize(train_values)\n",
    "y_train = np.array(train2[\"label\"])\n",
    "#Normalise values and change to numpy array\n",
    "x_test = preprocessing.normalize(test_values)\n",
    "y_test = np.array(test2[\"label\"])\n",
    "# Set up model to fit with specified paremeters (parameters will change depnding on the BERT model used)\n",
    "model2 = SVC(C=1,gamma = 1,probability = True,class_weight = 'balanced')\n",
    "# Fit model\n",
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3933f8",
   "metadata": {},
   "source": [
    "Test model (binary classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d00f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5479345284489477\n"
     ]
    }
   ],
   "source": [
    "# Get predicted values given the testing statements\n",
    "pred = model2.predict(x_test)\n",
    "# Prints the accuracy score of the classifier on the test dataset\n",
    "# Compares actual values (y_test) to predicted values (pred)\n",
    "print(accuracy_score(y_test , pred))\n",
    "# optional save to file\n",
    "#filename = ''\n",
    "#pickle.dump(model2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d697b4d",
   "metadata": {},
   "source": [
    "Load and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785e6d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset liar (C:/Users/Amy/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccd5e61b2024b8a86c894dcf43c5a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"liar\")\n",
    "training = dataset[\"train\"]\n",
    "testing = dataset[\"test\"]\n",
    "train = pd.DataFrame(training)\n",
    "test = pd.DataFrame(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba281b65",
   "metadata": {},
   "source": [
    "Training for 6 label classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c62970b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\AppData\\Local\\Temp\\ipykernel_11124\\2193091684.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"statement\"][i] = removed\n",
      "C:\\Users\\Amy\\AppData\\Local\\Temp\\ipykernel_11124\\2193091684.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"statement\"][i] = removed\n"
     ]
    }
   ],
   "source": [
    "# Training data preprocessing\n",
    "for i in range(len(train.index)):\n",
    "    # Remove punctuation\n",
    "    removed = re.sub(r'[^\\w\\s]', '', train[\"statement\"][i].lower())\n",
    "    train[\"statement\"][i] = removed\n",
    "train2 = train[[\"label\"]].copy()\n",
    "values = []\n",
    "for i in range(len(train.index)):\n",
    "    # Tokenise text\n",
    "    state = tokenizer.encode(train[\"statement\"][i] , return_tensors = \"pt\")\n",
    "    # Run tokenised text through BERT model\n",
    "    state = model(state)\n",
    "    # Get values and append to list\n",
    "    values.append(state.logits.detach().numpy())\n",
    "train_values =  np.concatenate(values)\n",
    "#Testing data preprocessing\n",
    "for i in range(len(test.index)):\n",
    "    # Remove punctuation\n",
    "    removed = re.sub(r'[^\\w\\s]', '', test[\"statement\"][i].lower())\n",
    "    test[\"statement\"][i] = removed\n",
    "test2 = test[[\"label\"]].copy()\n",
    "values = []\n",
    "for i in range(len(test.index)):\n",
    "    # Tokenise text\n",
    "    state = tokenizer.encode(test[\"statement\"][i] , return_tensors = \"pt\")\n",
    "    # Run tokenised text through BERT model\n",
    "    state = model(state)\n",
    "    # Get values and append to list\n",
    "    values.append(state.logits.detach().numpy())\n",
    "test_values =  np.concatenate(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070ac25",
   "metadata": {},
   "source": [
    "Fitting the model (6 label classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df2e73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, class_weight='balanced', gamma=0.1, kernel='linear',\n",
       "    probability=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalise values and change to numpy array\n",
    "x_train = preprocessing.normalize(train_values)\n",
    "y_train = np.array(train2[\"label\"])\n",
    "#Normalise values and change to numpy array\n",
    "x_test = preprocessing.normalize(test_values)\n",
    "y_test = np.array(test2[\"label\"])\n",
    "# Set up model to fit with specified paremeters (parameters will change depnding on the BERT model used)\n",
    "model2 = SVC(C=0.1,gamma =0.1,probability = True,class_weight = 'balanced',kernel = 'linear')\n",
    "# Fit model\n",
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffedd83d",
   "metadata": {},
   "source": [
    "Test model (6 label classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53c6353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21200311769290725\n"
     ]
    }
   ],
   "source": [
    "# Get predicted values given the testing statements\n",
    "pred = model2.predict(x_test)\n",
    "# Prints the accuracy score of the classifier on the test dataset\n",
    "# Compares actual values (y_test) to predicted values (pred)\n",
    "print(accuracy_score(y_test , pred))\n",
    "# optional save to file\n",
    "#filename = ''\n",
    "#pickle.dump(model2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a66b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
